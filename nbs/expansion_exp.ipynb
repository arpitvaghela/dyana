{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from numpy import cos, sin\n",
    "import numpy as np\n",
    "from grok.transformer import MultiHeadAttention, LayerNorm, FFN, Transformer\n",
    "from typing import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0678, 0.4101, 0.8137],\n",
       "        [0.1975, 0.9752, 0.2417],\n",
       "        [0.3470, 0.9060, 0.8533],\n",
       "        [0.6832, 0.1224, 0.2610]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = 100\n",
    "x = th.tensor([5,11,6, 66])\n",
    "embedding_weight = th.rand((vocab_len,3))\n",
    "F.embedding(x, embedding_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[slice(None, 100, None), slice(None, 3, None)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0678, 0.4101, 0.8137, 0.0000],\n",
       "        [0.1975, 0.9752, 0.2417, 0.0000],\n",
       "        [0.3470, 0.9060, 0.8533, 0.0000],\n",
       "        [0.6832, 0.1224, 0.2610, 0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weight_exp = th.zeros((vocab_len,4))\n",
    "size = embedding_weight.shape\n",
    "size = [slice(x) for x in size]\n",
    "print(size)\n",
    "embedding_weight_exp[size] = embedding_weight\n",
    "F.embedding(x, embedding_weight_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Embedding Layer with positional encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0100,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
       "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
       "        [-0.7568, -0.6536,  0.0400,  0.9992]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_position_encoding(context_len: int, d_model: int) -> th.Tensor:\n",
    "        rows = [\n",
    "            th.tensor(\n",
    "                [\n",
    "                    sin(pos / (10000 ** (i / d_model)))\n",
    "                    if i % 2 == 0\n",
    "                    else cos(pos / (10000 ** ((i - 1) / d_model)))\n",
    "                    for i in range(d_model)\n",
    "                ]\n",
    "            )\n",
    "            for pos in range(context_len)\n",
    "        ]\n",
    "        stack = th.stack(rows, dim=1)\n",
    "\n",
    "        return stack.T  # type: ignore\n",
    "gen_position_encoding(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(indices: th.Tensor, embedding_weight:th.Tensor, position_encoding:th.Tensor) -> th.Tensor:\n",
    "        context_len = indices.shape[-1]\n",
    "        pe = position_encoding[:context_len, :]  # type: ignore\n",
    "        embedded = F.embedding(indices,embedding_weight)\n",
    "        return pe + embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0678,  1.4101,  0.8137],\n",
       "        [ 1.0390,  1.5155,  0.2439],\n",
       "        [ 1.2563,  0.4899,  0.8576],\n",
       "        [ 0.8243, -0.8675,  0.2674]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(x, embedding_weight, gen_position_encoding(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0678,  1.4101,  0.8137,  1.0000],\n",
       "        [ 1.0390,  1.5155,  0.2517,  1.0000],\n",
       "        [ 1.2563,  0.4899,  0.8733,  0.9998],\n",
       "        [ 0.8243, -0.8675,  0.2910,  0.9996]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(x, embedding_weight_exp, gen_position_encoding(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Decoder Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head Expansion logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_emb(self, i):\n",
    "    return self.embedding(i)\n",
    "\n",
    "Transformer.embed = new_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = Transformer(n_layers=1, n_heads=3, d_model=12)\n",
    "net1.d_model//net1.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(net1, \"./checkpoints/net1.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position_encoding\n",
      "self_attn_mask\n",
      "embedding.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.0.Wq.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.0.Wk.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.0.Wv.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.1.Wq.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.1.Wk.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.1.Wv.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.2.Wq.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.2.Wk.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.2.Wv.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.3.Wq.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.3.Wk.weight\n",
      "decoder.blocks.0.self_attn.attn_heads.3.Wv.weight\n",
      "decoder.blocks.0.self_attn.Wo.weight\n",
      "decoder.blocks.0.self_attn_norm.weight\n",
      "decoder.blocks.0.self_attn_norm.bias\n",
      "decoder.blocks.0.ffn.ffn.0.weight\n",
      "decoder.blocks.0.ffn.ffn.2.weight\n",
      "decoder.blocks.0.ffn_norm.weight\n",
      "decoder.blocks.0.ffn_norm.bias\n",
      "decoder.blocks.1.self_attn.attn_heads.0.Wq.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.0.Wk.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.0.Wv.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.1.Wq.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.1.Wk.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.1.Wv.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.2.Wq.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.2.Wk.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.2.Wv.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.3.Wq.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.3.Wk.weight\n",
      "decoder.blocks.1.self_attn.attn_heads.3.Wv.weight\n",
      "decoder.blocks.1.self_attn.Wo.weight\n",
      "decoder.blocks.1.self_attn_norm.weight\n",
      "decoder.blocks.1.self_attn_norm.bias\n",
      "decoder.blocks.1.ffn.ffn.0.weight\n",
      "decoder.blocks.1.ffn.ffn.2.weight\n",
      "decoder.blocks.1.ffn_norm.weight\n",
      "decoder.blocks.1.ffn_norm.bias\n",
      "linear.weight\n"
     ]
    }
   ],
   "source": [
    "def knowledge_transfer(net2:th.nn.Module, old_state_path:str):\n",
    "    net1 = th.load(old_state_path)\n",
    "    old_state = net1.state_dict()\n",
    "    n_layers_old = net1.n_layers\n",
    "    n_head_old = net1.n_heads\n",
    "\n",
    "    dk_old = net1.d_model//net1.n_heads\n",
    "    dk_new = net2.d_model//net2.n_heads\n",
    "\n",
    "    new_state = net2.state_dict() \n",
    "    updated_state = deepcopy(new_state)\n",
    "    for k in new_state:\n",
    "        # print(k)\n",
    "        if k == \"position_encoding\" or k == \"self_attn_mask\":\n",
    "            continue\n",
    "        elif \"self_attn_norm\" in k.split(\".\") or \"ffn_norm\" in k.split(\".\"):\n",
    "            continue\n",
    "        elif \"attn_heads\" in k.split(\".\"):\n",
    "            updated_state[k] = th.zeros_like(new_state[k])\n",
    "            weight_name = k.split(\".\")\n",
    "            layer_idx = int(weight_name[2])\n",
    "            if layer_idx < n_layers_old:\n",
    "                head_idx = int(weight_name[5])   \n",
    "                lst = [(i//dk_old, i%dk_old) for i in (head_idx*dk_new, head_idx*dk_new +dk_new)]\n",
    "                w = []\n",
    "                if lst[0][0] == lst[1][0]:\n",
    "                    w.append(old_state[k][ lst[0][1]: lst[1][1], :])\n",
    "                else:\n",
    "                    for prev_head_idx in range(lst[0][0], lst[1][0]+1):\n",
    "                        if not prev_head_idx < n_head_old:\n",
    "                            continue\n",
    "                        weight_name_old = weight_name.copy()\n",
    "                        weight_name_old[5] = str(prev_head_idx)\n",
    "                        k_old = \".\".join(weight_name_old)\n",
    "\n",
    "                        if prev_head_idx == lst[0][0]:\n",
    "                            w_dash = old_state[k_old][lst[0][1]: , :]\n",
    "                            # print(rng,w_dash.shape)\n",
    "                            w.append(w_dash)\n",
    "\n",
    "                        elif prev_head_idx == lst[1][0]:\n",
    "                            w_dash = old_state[k_old][ :lst[1][1], :]\n",
    "                            # print(rng, w_dash.shape)\n",
    "                            w.append(w_dash)\n",
    "                        else:\n",
    "                            w.append(old_state[k_old])\n",
    "                    if w:\n",
    "                        final_old_w = th.cat(w)\n",
    "                        dice = [slice(dim) for dim in final_old_w.shape]\n",
    "                        updated_state[k][dice] = final_old_w\n",
    "        else:\n",
    "            updated_state[k] = th.zeros_like(new_state[k])\n",
    "            if k in old_state:\n",
    "                dice = [slice(dim) for dim in old_state[k].shape]\n",
    "                updated_state[k][dice] = old_state[k]\n",
    "        \n",
    "    net2.load_state_dict(updated_state)\n",
    "\n",
    "net2 = Transformer(n_layers=2, n_heads=4, d_model=16)\n",
    "knowledge_transfer(net2, \"./checkpoints/net1.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in updated_state:\n",
    "#     print(k, updated_state[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8888, -0.2345, -0.5484,  0.7895, -0.6686, -0.7335,  0.7221,  0.9016,\n",
       "           0.0201, -0.4690, -1.0916, -0.4233]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 0.8888, -0.2345, -0.5484,  0.7895, -0.6686, -0.7335,  0.7221,  0.9016,\n",
       "           0.0201, -0.4690, -1.0916, -0.4233,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = th.tensor([11])\n",
    "em1 = net1.embed(x)\n",
    "em2 = net2.embed(x)\n",
    "em1, em2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[-0.1011,  0.1441,  0.2920, -0.2969,  0.0155, -0.1035, -0.0443,  0.3187,\n",
       "            0.0517, -0.1360, -0.1360,  0.1196]], grad_fn=<MmBackward0>),\n",
       "  [],\n",
       "  []),\n",
       " (tensor([[-0.1011,  0.1441,  0.2920, -0.2969,  0.0155, -0.1035, -0.0443,  0.3187,\n",
       "            0.0517, -0.1360, -0.1360,  0.1196,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "         grad_fn=<MmBackward0>),\n",
       "  [],\n",
       "  []))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.decoder.blocks[0].self_attn(em1,em1,em1), net2.decoder.blocks[0].self_attn(em2,em2,em2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 1.1587,  0.1066, -0.3665,  0.5919, -0.7335, -0.8723,  0.8522,  2.0088,\n",
       "            0.1278, -0.6590, -1.8812, -0.3333]],\n",
       "         grad_fn=<NativeLayerNormBackward0>),\n",
       "  [],\n",
       "  []),\n",
       " (tensor([[ 1.2905,  0.0695, -0.2614,  0.6270, -0.9105, -1.0636,  0.9250,  2.2703,\n",
       "            0.0870, -0.8132, -2.2329, -0.4385,  0.1127,  0.1127,  0.1127,  0.1127]],\n",
       "         grad_fn=<NativeLayerNormBackward0>),\n",
       "  [],\n",
       "  []))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.decoder.blocks[0](em1), net2.decoder.blocks[0](em2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8888, -0.2345, -0.5484,  0.7895, -0.6686, -0.7335,  0.7221,  0.9016,\n",
       "           0.0201, -0.4690, -1.0916, -0.4233,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " (tensor([[ 1.5869, -0.3060, -0.8350,  1.4196, -1.0375, -1.1468,  1.3061,  1.6084,\n",
       "            0.1231, -0.7012, -1.7502, -0.6241,  0.0892,  0.0892,  0.0892,  0.0892]],\n",
       "         grad_fn=<NativeLayerNormBackward0>),\n",
       "  [],\n",
       "  []))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em2, net2.decoder.blocks[1](em2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.3740,  0.0282, -0.2062,  ..., -0.5324, -0.6836, -0.3312]],\n",
       "         grad_fn=<MmBackward0>),\n",
       "  [],\n",
       "  []),\n",
       " (tensor([[ 0.5021,  0.0963, -0.3351,  ..., -0.6437, -0.8326, -0.3108]],\n",
       "         grad_fn=<MmBackward0>),\n",
       "  [],\n",
       "  []))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1(x), net2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = th.nn.LayerNorm(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8888, -0.2345, -0.5484,  0.7895, -0.6686, -0.7335,  0.7221,  0.9016,\n",
       "           0.0201, -0.4690, -1.0916, -0.4233,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 1.5869, -0.3060, -0.8350,  1.4196, -1.0375, -1.1468,  1.3061,  1.6084,\n",
       "           0.1231, -0.7012, -1.7502, -0.6241,  0.0892,  0.0892,  0.0892,  0.0892]],\n",
       "        grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em2, norm(em2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.decoder.blocks[0].self_attn_norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8888, -0.2345, -0.5484,  0.7895, -0.6686, -0.7335,  0.7221,  0.9016,\n",
       "           0.0201, -0.4690, -1.0916, -0.4233,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 1.5869, -0.3060, -0.8350,  1.4196, -1.0375, -1.1468,  1.3061,  1.6084,\n",
       "           0.1231, -0.7012, -1.7502, -0.6241,  0.0892,  0.0892,  0.0892,  0.0892]],\n",
       "        grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em2, F.layer_norm(em2, (16,), norm_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11b01b9c5b8ff60b99e90016c0fc35672e8bff0e840ae7e3fc812494c63e782d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
